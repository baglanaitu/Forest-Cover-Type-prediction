{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.read_csv(\"../input/dmmlassignment2/x_train.csv\")\ny=pd.read_csv(\"../input/dmml-assignment/y_train.csv\")\nactual_dataset = pd.read_csv(\"../input/dmml-assignment/x_test.csv\")\n#y_test = pd.read_csv(\"../input/dmmlassignment2/y_test_baseline.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[X.columns[1:]]\nX.columns = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_1', 'Wilderness_Area_2', 'Wilderness_Area_3', 'Wilderness_Area_4', \n'Soil_Type_1', 'Soil_Type_2','Soil_Type_3','Soil_Type_4','Soil_Type_5','Soil_Type_6','Soil_Type_7','Soil_Type_8','Soil_Type_9','Soil_Type_10',\n'Soil_Type_11','Soil_Type_12','Soil_Type_13','Soil_Type_14','Soil_Type_15','Soil_Type_16','Soil_Type_17','Soil_Type_18','Soil_Type_19','Soil_Type_20',\n'Soil_Type_21','Soil_Type_22','Soil_Type_23','Soil_Type_24','Soil_Type_25','Soil_Type_26','Soil_Type_27','Soil_Type_28','Soil_Type_29','Soil_Type_30',\n'Soil_Type_31','Soil_Type_32','Soil_Type_33','Soil_Type_34','Soil_Type_35','Soil_Type_36','Soil_Type_37','Soil_Type_38','Soil_Type_39','Soil_Type_40']\n\nactual_dataset = actual_dataset[actual_dataset.columns[1:]]\nactual_dataset.columns = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area_1', 'Wilderness_Area_2', 'Wilderness_Area_3', 'Wilderness_Area_4', \n'Soil_Type_1', 'Soil_Type_2','Soil_Type_3','Soil_Type_4','Soil_Type_5','Soil_Type_6','Soil_Type_7','Soil_Type_8','Soil_Type_9','Soil_Type_10',\n'Soil_Type_11','Soil_Type_12','Soil_Type_13','Soil_Type_14','Soil_Type_15','Soil_Type_16','Soil_Type_17','Soil_Type_18','Soil_Type_19','Soil_Type_20',\n'Soil_Type_21','Soil_Type_22','Soil_Type_23','Soil_Type_24','Soil_Type_25','Soil_Type_26','Soil_Type_27','Soil_Type_28','Soil_Type_29','Soil_Type_30',\n'Soil_Type_31','Soil_Type_32','Soil_Type_33','Soil_Type_34','Soil_Type_35','Soil_Type_36','Soil_Type_37','Soil_Type_38','Soil_Type_39','Soil_Type_40']\n\ny = y[y.columns[1:]]\ny.columns=['Cover_Type']\n\n# Data cleaning\nrem = []\nfor c in X.columns:\n    if X[c].std() == 0: #standard deviation is zero\n        rem.append(c)\nX.drop(rem,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.concat([X, y], axis=1)\ndataset.groupby('Cover_Type').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(dataset['Horizontal_Distance_To_Hydrology']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = dataset.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_size = 198310\n\nlst = [dataset]\nfor class_index, group in dataset.groupby('Cover_Type'):\n    lst.append(group.sample(max_size-len(group), replace=True))\ndataset = pd.concat(lst)\n\ny = dataset.iloc[:, -1:]\nX = dataset.iloc[:,:-1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing rows with missing value\n\nfrom numpy import nan\n\nresult = pd.concat([X, y], axis=1)\nprint(result.shape) # number of matrix before removing rows with zero values\nresult[[\"Horizontal_Distance_To_Fire_Points\"]] = result[[\"Horizontal_Distance_To_Fire_Points\"]].replace(0, nan)\nresult.dropna(inplace=True)\n#result.fillna(result[[\"Horizontal_Distance_To_Fire_Points\"]].mean(), inplace=True)\n\nresult[[\"Aspect\"]] = result[[\"Aspect\"]].replace(0, nan)\nresult.dropna(inplace=True)\n#result.fillna(result[[\"Aspect\"]].mean(), inplace=True)\n\nresult.fillna(result.mean(), inplace=True)\n\n\ny = result.iloc[:, -1:]\nX = result.iloc[:,:-1] \nprint(y.shape)\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization between highly correlated attributes\nresult = pd.concat([X[\"Hillshade_9am\"],X[\"Hillshade_3pm\"]], axis=1)\nresult=((result-result.min())/(result.max()-result.min()))*2\nX[\"Hillshade_9am\"] = result.iloc[:, :-1]\nX[\"Hillshade_3pm\"] = result.iloc[:, -1]\n\nresult = pd.concat([X['Horizontal_Distance_To_Hydrology'],X['Vertical_Distance_To_Hydrology']], axis=1)\nresult=((result-result.min())/(result.max()-result.min()))*2\nX['Horizontal_Distance_To_Hydrology'] = result.iloc[:, :-1]\nX['Vertical_Distance_To_Hydrology'] = result.iloc[:, -1]\n\nresult = pd.concat([X['Slope'],X['Hillshade_Noon']], axis=1)\nresult=((result-result.min())/(result.max()-result.min()))*2\nX['Slope'] = result.iloc[:, :-1]\nX['Hillshade_Noon'] = result.iloc[:, -1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalization\nX=((X-X.min())/(X.max()-X.min()))*2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.boxplot(x=X['Slope'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing outliers from Slope\nmedian_X = X['Slope'].median()\nX['Slope'] = np.where(X['Slope'] < median_X, median_X, X['Slope'])"},{"metadata":{},"cell_type":"markdown","source":"# Removing outliers from Horizontal_Distance_To_Hydrology\nmedian_H = X['Horizontal_Distance_To_Hydrology'].median()\nX['Horizontal_Distance_To_Hydrology'] = np.where(X['Horizontal_Distance_To_Hydrology'] < median_H, median_H, X['Horizontal_Distance_To_Hydrology'])"},{"metadata":{},"cell_type":"markdown","source":"# Removing outliers from Vertical_Distance_To_Hydrology\nmedian_V = X['Vertical_Distance_To_Hydrology'].median()\nX['Vertical_Distance_To_Hydrology'] = np.where(X['Vertical_Distance_To_Hydrology'] < median_V, median_V, X['Vertical_Distance_To_Hydrology'])"},{"metadata":{},"cell_type":"markdown","source":"# Removing outliers from 'Horizontal_Distance_To_Roadways'\nmedian_V = X['Horizontal_Distance_To_Roadways'].median()\nX['Horizontal_Distance_To_Roadways'] = np.where(X['Horizontal_Distance_To_Roadways'] < median_V, median_V, X['Horizontal_Distance_To_Roadways'])"},{"metadata":{},"cell_type":"markdown","source":"# Removing outliers from 'Hillshade_9am'\nmedian_V = X['Hillshade_9am'].median()\nX['Hillshade_9am'] = np.where(X['Hillshade_9am'] < median_V, median_V, X['Hillshade_9am'])"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing outliers from y_train\nmedian = y.loc[y['Cover_Type']<3, 'Cover_Type'].median()\ny['Cover_Type'] = np.where(y['Cover_Type'] > median, median, y['Cover_Type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(y['Cover_Type']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 10, stratify=y['Cover_Type'])\n# test_size = 0.30, random state = 10\nx_train.reset_index(drop=True, inplace=True)\ny_train.reset_index(drop=True, inplace=True)\nx_test.reset_index(drop=True, inplace=True)\ny_test.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# By far best result\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\n\n#Base estimator\nbase_estimator = DecisionTreeClassifier(random_state=10,max_depth=13)\n\nn_list = [100]\n\nfor n_estimators in n_list:\n    #Set the base model\n    model = BaggingClassifier(n_jobs=-1,base_estimator=base_estimator, n_estimators=n_estimators, random_state=10)\n\nforest = BaggingClassifier(n_estimators=20) # initially 10\nforest.fit(x_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy score\nfrom sklearn.metrics import accuracy_score\n\ny_pred = forest.predict(actual_dataset)\n\n#y_pred = forest.predict(x_test)\n#print(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nindex = list(range(len(actual_dataset)))\ny_pred = y_pred.astype('int')\n\ndf = pd.DataFrame(data=np.vstack((index,y_pred)).T, index=index, columns=[\"id\",\"Cover_Type\"])\ndf.to_csv('NORM_result_2.csv',index=False)\n\n#df.to_csv('mycsvfile_5.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}